{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "hello_dora.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/lapalap/dora/6991c4a08f27e4171e3a9b0bdffc0a14966e07df/assets/images/logo.svg\" width=\"350\"/>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\"><h1>DORA: s-AMS generation for ImageNet networks</h1>\n",
    "<h5>This notebook demonstrates DORA's capability to analyze representation spaces of commonly used Computer Vision Architectures.</h5>"
   ],
   "metadata": {
    "id": "f3fNR3tAvrKd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEQBo6wuvh1v"
   },
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/lapalap/dora.git --quiet\n",
    "! pip install umap-learn --quiet\n",
    "! pip install timm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from dora import Dora\n",
    "from dora.objectives import ChannelObjective\n",
    "\n",
    "from timm import create_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "id": "ZYErd2mBZm00"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ðŸ¤– Initializing Computer Vision Models"
   ],
   "metadata": {
    "id": "QFP0IrN4Zqhl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_model(model_name):\n",
    "    if model_name == 'resnet18':\n",
    "        return models.resnet18(pretrained=True).to(device)\n",
    "    if model_name == 'alexnet':\n",
    "        return models.alexnet(pretrained=True).to(device)\n",
    "    if model_name == 'vit_base_patch16_224':\n",
    "        return create_model('vit_base_patch16_224', pretrained=True).to(device)\n",
    "    if model_name == 'beit_base_patch16_224':\n",
    "        return create_model('beit_base_patch16_224', pretrained=True).to(device)\n",
    "    if model_name == 'inception_v3':\n",
    "        return models.inception_v3(pretrained=True).to(device)\n",
    "    if model_name == 'densenet161':\n",
    "        return models.densenet161(pretrained=True).to(device)\n",
    "    if model_name == 'mobilenet_v2':\n",
    "        return models.mobilenet_v2(pretrained=True).to(device)\n",
    "    if model_name == 'shufflenet_v2_x1_0':\n",
    "        return models.shufflenet_v2_x1_0(pretrained=True).to(device)\n",
    "\n",
    "model_names = ['resnet18',\n",
    "               'alexnet',\n",
    "               'vit_base_patch16_224',\n",
    "               'beit_base_patch16_224',\n",
    "               'inception_v3',\n",
    "               'densenet161',\n",
    "               'mobilenet_v2',\n",
    "               'shufflenet_v2_x1_0'\n",
    "]"
   ],
   "metadata": {
    "id": "KsR9Uml-sJaW"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ðŸ–¼ Generating s-AMS\n",
    "Here we iteratively generate s-AMS signals for the output representations of popular ImageNet pre-trained Computer Vision models. NOTE: it will take some time"
   ],
   "metadata": {
    "id": "3IUJmNFHZ8AV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "k = 1000\n",
    "n = 3\n",
    "neuron_indices = [i for i in range(0, k)]\n",
    "\n",
    "for model_name in model_names:\n",
    "\n",
    "  model = get_model(model_name).eval()\n",
    "  \n",
    "  d = Dora(model=model,\n",
    "          storage_dir=\"dora/\",\n",
    "          device=device)\n",
    "  \n",
    "  experiment_name = model_name\n",
    "\n",
    "  d.generate_signals(\n",
    "        neuron_idx=neuron_indices,\n",
    "        num_samples = n,\n",
    "        layer=model,\n",
    "        only_maximization = True,\n",
    "        image_transforms = transforms.Compose([transforms.Pad(2, fill=.5, padding_mode='constant'),\n",
    "                                              transforms.RandomAffine(0, translate=(0.015, 0.015), fill=0.5),\n",
    "                                              transforms.RandomAffine(0, translate=(0.015, 0.015), fill=0.5),\n",
    "                                              transforms.RandomAffine(0, translate=(0.015, 0.015), fill=0.5),\n",
    "                                              transforms.RandomAffine(0, translate=(0.015, 0.015), fill=0.5),\n",
    "                                              transforms.RandomAffine(0, translate=(0.015, 0.015), fill=0.5),\n",
    "                                              transforms.RandomAffine(0, translate=(0.015, 0.015), fill=0.5),\n",
    "                                              transforms.RandomAffine(0, translate=(0.015, 0.015), fill=0.5),\n",
    "                                              transforms.RandomAffine(0, translate=(0.015, 0.015), fill=0.5),\n",
    "                                              transforms.RandomAffine(0, translate=(0.015, 0.015), fill=0.5),\n",
    "                                              transforms.RandomAffine(0, translate=(0.015, 0.015), fill=0.5),\n",
    "                                              transforms.RandomAffine((-20,20),\n",
    "                                                                      scale=(0.75, 1.025),\n",
    "                                                                      fill=0.5),\n",
    "                                              transforms.RandomCrop((224, 224),\n",
    "                                                                    padding=None,\n",
    "                                                                    pad_if_needed=True,\n",
    "                                                                    fill=0,\n",
    "                                                                    padding_mode='constant')]),\n",
    "        objective_fn=ChannelObjective(),\n",
    "        lr=0.05,\n",
    "        width=224,\n",
    "        height=224,\n",
    "        iters=500,\n",
    "        experiment_name=experiment_name,\n",
    "        overwrite_experiment=True,  ## will still use what already exists if generation params are same\n",
    "    )"
   ],
   "metadata": {
    "id": "-xJtSFz8ZWuv"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}